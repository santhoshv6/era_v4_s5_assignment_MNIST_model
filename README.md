# MNIST CNN Classifier - Session 5 Assignment

## ğŸ“Œ Overview

This project implements a **lightweight Convolutional Neural Network (CNN)** classifier for the **MNIST digit recognition** task.

### Key Highlights

* **Parameter Efficiency**: < 20,000 trainable parameters (**17,682 total**)
* **Modern CNN Techniques**: Batch Normalization, Dropout, Global Average Pooling
* **High Accuracy**: > **99.4% test accuracy** in under **20 training epochs**

---

## ğŸ—ï¸ Model Architecture

### ğŸ”‘ Key Components

1. **Depthwise Separable Convolutions (DSConv)** â€“ efficient convolution blocks
2. **Squeeze-and-Excitation (SE) Module** â€“ channel-wise attention
3. **Global Average Pooling (GAP)** â€“ spatial dimension reduction
4. **Batch Normalization** â€“ stabilizes and accelerates training
5. **Dropout** â€“ regularization to prevent overfitting (p = 0.03)

### âš™ï¸ Architecture Details

* **Input**: 28Ã—28 grayscale images
* **Stem**: Initial Conv â†’ BatchNorm â†’ ReLU
* **Blocks**: 4 DSConv blocks with channels: **16 â†’ 32 â†’ 64 â†’ 96**
* **Pooling**: MaxPooling layers for downsampling
* **Output**: 10-class softmax (digits 0â€“9)

---

## âš¡ Training Configuration

* **Optimizer**: SGD with momentum (0.9), weight decay (5e-4)
* **Scheduler**: OneCycleLR
* **Loss Function**: CrossEntropyLoss
* **Data Augmentation**: Random rotations & affine transforms
* **Early Stopping**: Triggered at 99.4% test accuracy

---

## ğŸ† Results

### âœ… Summary

* **Total Parameters**: 17,682 (< 20,000 requirement)
* **Best Test Accuracy**: **99.44%**
* **Training Epochs**: 19 (early stopping before 20)

### ğŸ“Š Training Progress

| Epoch | Train Loss | Train Acc | Test Loss | Test Acc | Best Model |
| ----- | ---------- | --------- | --------- | -------- | ---------- |
| 1     | 0.6188     | 80.62%    | 0.1953    | 93.75%   | âœ… Saved    |
| 2     | 0.1041     | 96.91%    | 0.0865    | 97.47%   | âœ… Saved    |
| 5     | 0.0660     | 98.00%    | 0.0778    | 97.59%   | âœ… Saved    |
| 11    | 0.0529     | 98.47%    | 0.0761    | 97.60%   | âœ… Saved    |
| 12    | 0.0508     | 98.48%    | 0.0632    | 98.04%   | âœ… Saved    |
| 13    | 0.0489     | 98.57%    | 0.0423    | 98.87%   | âœ… Saved    |
| 16    | 0.0366     | 99.00%    | 0.0353    | 98.89%   | âœ… Saved    |
| 17    | 0.0321     | 99.09%    | 0.0300    | 99.23%   | âœ… Saved    |
| 18    | 0.0271     | 99.26%    | 0.0225    | 99.36%   | âœ… Saved    |
| 19    | 0.0226     | 99.35%    | 0.0213    | 99.44%   | âœ… Saved    |

### ğŸ¯ Key Achievements

* **Final Test Accuracy**: 99.44% (exceeded target)
* **Training Efficiency**: Achieved target in < 20 epochs
* **Stable Training**: No overfitting observed

---

## ğŸ” Model Analysis

### Analysis Results (via `model_analysis.py`)

| Requirement             | Check                              | Status   |
| ----------------------- | ---------------------------------- | -------- |
| **Total Parameters**    | 17,682 (< 20k)                     | âœ… PASSED |
| **Batch Normalization** | 4 layers (Stem + DSConv blocks)    | âœ… PASSED |
| **Dropout**             | 1 layer, p=0.03                    | âœ… PASSED |
| **GAP / FC Layer**      | AdaptiveAvgPool2d + Linear (96â†’10) | âœ… PASSED |

---

## ğŸ“‚ Files

* `S5_assignment_final.ipynb` â†’ Model implementation + training
* `model_analysis.py` â†’ Script for verifying model requirements
* `README.md` â†’ Documentation (this file)

---

## ğŸš€ Usage

1. Run training notebook:

   ```bash
   jupyter notebook S5_assignment_final.ipynb
   ```
2. Run analysis script:

   ```bash
   python model_analysis.py
   ```
3. View results in `model_analysis_results.json`

---

## ğŸ“ˆ Technical Implementation

* Depthwise separable convolutions â†’ parameter efficiency
* Squeeze-and-Excitation â†’ channel attention
* Dilated convolutions â†’ larger receptive field
* OneCycleLR scheduler â†’ optimal LR scheduling
* Gradient clipping â†’ stable training

---

## ğŸ“ Performance Metrics

* **Training Accuracy**: > 98%
* **Test Accuracy**: > 99.4%
* **Training Time**: \~19 epochs (early stopped)
* **Model Size**: \~2.41 MB

---

## ğŸ“œ License

This project is released for educational purposes under **ERA V4 - Session 5 Assignment** guidelines.

---